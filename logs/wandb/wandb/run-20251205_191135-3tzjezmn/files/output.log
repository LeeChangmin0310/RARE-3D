ppo train:   0%|          | 0/2000 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/cia/disk1/bci_intern/AAAI2026/RLDoom/train.py", line 87, in <module>
    main()
  File "/home/cia/disk1/bci_intern/AAAI2026/RLDoom/train.py", line 80, in main
    train_onpolicy(agent, cfg, logger)
  File "/home/cia/disk1/bci_intern/AAAI2026/RLDoom/rldoom/trainers/onpolicy.py", line 54, in train_onpolicy
    metrics: Dict[str, Any] = agent.update()
  File "/home/cia/disk1/bci_intern/AAAI2026/RLDoom/rldoom/agents/ppo.py", line 110, in update
    assert total_steps >= batch_size, "Rollout too short for PPO batch"
AssertionError: Rollout too short for PPO batch
